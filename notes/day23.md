## [Day 23] 군집 탐색 & 추천시스템 (기초)
### [Graph 5강] 그래프의 구조를 어떻게 분석할까?
#### 1. 군집 구조와 군집 탐색 문제
+ 군집(Community)란 다음 조건들을 만족하는 정점들의 집함
    + 집합에 속하는 정점 사이에는 많은 간선이 존재함
    + 집합에 속하는 정점과 그렇지 않은 정점 사이에는 적은 수의 간선이 존재함
+ 온라인 소셜 네트워크의 군집들은 사회적 무리(Social Circle)을 의미하는 경우가 있음
+ 조직 내의 분란이 소셜 네트워크 상의 군집으로 표현될 수 있음
+ 회사내 이메일 네트워크, 보고체계 등을 분석하여 회사내 커뮤니케이션이 얼마나 복잡한지 알 수 있음
+ 뉴런과 연결 그래프에서는 군집들이 뇌의 기능적 구성 단위를 의미
+ 그래프를 여러 군집으로 '잘' 나누는 문제를 군집 탐색(Community Detection) 문제라고 함
#### 2. 비교대상 : 배치 모형
+ 성공적인 군집 탐색을 정의하기 위해 먼저 배치 모형(Configuration Model)을 소개함
+ 간선들을 무작위로 재배치하여 얻은 그래프
+ 배치 모형에서 임의의 두 정점 i와 j사이에 간선이 존재할 확률은 두 정점의 연결성에 비례함

![캡처](https://user-images.githubusercontent.com/44515744/108931183-8f7f9680-768a-11eb-979b-394195f14191.PNG)

#### 3. 군집성의 정의
+ 군집 탐색의 성공 여부를 판단하기 위해서, 군집성(Modularity)가 사용됨
+ 그래프와 군집들의 집합 S가 주어짐
+ S의 각 군집이 군집의 성질을 잘 만족하는 지를 살펴보기 위해, 군집 내부의 간선의 수를 그래프와 배치 모형에서 비교
+ 군집성은 다음 수식으로 계산됨
+ 각 군집에 대하여 주어진 입력그래프에서 군집 내부 간선의 수, 배치 모형에서 군집 s 내부 간선의 수의 기댓값을 뺌
    + 기댓값을 사용하는 것은 배치 모형이 무작위성을 갖고있기 때문
    + 이 차이가 크면클수록 좋음
    + 마지막으로 정규화 과정을 거쳐서 군집성이 -1 과 1 사이의 값을 갖게됨
+ 군집성을 무작위로 연결된 배치 모형과 비교를 통해 통계적 유의성을 판단함
+ 군집성은 항상 -1과 +1 사이의 값을 가짐
+ 보통 군집성이 0.3 ~ 0.7 정도의 값을 가질 때, 그래프에 존재하는 통계적으로 유의미한 군집들을 찾아냈다고 할 수 있음

![캡처](https://user-images.githubusercontent.com/44515744/108932817-585eb480-768d-11eb-90bc-056cc14815e1.PNG)

#### 4. Girvan-Newman 알고리즘
+ 대표적인 하향식(Top-Down) 군집 탐색 알고리즘
+ Girvan-Newman 알고리즘은 전체 그래프에서 탐색을 시작
+ 군집들이 서로 분리되도록, 간선을 순차적으로 제거함
+ 오른쪽 예시에서 서로 다른 군집을 연결하는 다리(Bridge) 역할의 간선을 제거함

![캡처](https://user-images.githubusercontent.com/44515744/108933218-1bdf8880-768e-11eb-96fb-a215397f0bc0.PNG)

+ 서로 다른 군집을 연결하는 다리 역할의 간선을 찾는 방법?
+ 간선의 매개 중심성(Betweenness Centrality)을 사용함
+ 이는 해당 간선이 정점 간의 최단 경로에 놓이는 횟수를 의미

![캡처](https://user-images.githubusercontent.com/44515744/108933550-acb66400-768e-11eb-9513-4f94e2d64883.PNG)

+ 정점 i로 부터 j로의 최단 경로 수 중에서 간선 (x, y)를 포함한 것의 비율을 모든 정점쌍에 대해 더해줘서 매개 중심성을 구함

![캡처](https://user-images.githubusercontent.com/44515744/108933705-f2732c80-768e-11eb-9ac6-53c29e3827cf.PNG)

+ 매개 중심성을 통해 서로 다른 군집을 연결하는 다리 역할의 간선을 찾아낼 수 있음
+ Girvan-Newman 알고리즘은 매개 중심성이 높은 간선을 순차적으로 제거함
    + 간선이 제거될 때마다, 매개 중심성을 다시 계산하여 갱신함
+ 간선이 모두 제거될 때까지 이 과정을 반복
+ 간선의 제거 정도에 따라서 다른 입도(Granularity)의 군집 구조가 나타남
+ 군집성이 최대가 되는 지점까지 간선을 제거함
+ 현재의 연결 요소들을 군집으로 가정하되, 입력 그래프에서 군집성을 계산함

![캡처](https://user-images.githubusercontent.com/44515744/108934175-c310ef80-768f-11eb-84a6-a596249b10a7.PNG)

#### 5. Girvan-Newman 알고리즘 정리
+ 전체 그래프에서 시작
+ 매개 중심성이 높은 순서로 간선을 제거하면서, 군집성의 변화를 기록
+ 군집성이 가장 커지는 상황을 복원
+ 이 때, 서로 연결된 정점들, 즉 연결 요소를 하나의 군집으로 갖누
+ 즉 전체 그래프에서 시작해서 점점 작은 단위를 검색하는 하향식(Top-Down) 방법

#### 6. Louvain 알고리즘
+ Louvain 알고리즘은 대표적인 상향식(Bottom-up) 군집 탐색 알고리즘
+ 개별 정점에서 시작해서 점점 큰 군집을 형성함
+ 군집은 군집성을 사용해서 합침
+ 1) 개별 정점으로 구성된 크기 1의 군집들로부터 시작함
+ 2) 각 정점 u를 기존 혹은 새로운 군집으로 이동, 이 때, 군집성이 최대화되도록 군집을 결정
+ 3) 더 이상 군집성이 증가하지 않을 때까지 2)를 반복
+ 4) 각 군집을 하나의 정점으로하는 군집 레벨의 그래프를 얻은 뒤 3)을 수행
+ 5) 한 개의 정점이 남을 때까지 4)를 반복

#### 7. 중첩이 있는 군집 구조
+ 실제 그래프의 군집들은 중첩되어 있는 경우가 많음
+ Girvan-Newman 알고리즘과 Louvain 알고리즘은 군집 간의 중첩이 없다고 가정함

![캡처](https://user-images.githubusercontent.com/44515744/108936942-e0df5400-7691-11eb-8715-1dba98c22ae1.PNG)

#### 8. 중첩 군집 모형
+ 각 정점은 여러 개의 군집에 속할 수 있음
+ 각 군집 A에 대하여, 각 군집에 속하는 두 정점은 P_{A} 확률로 간선으로 직접 연결됨
+ 두 정점이 여러 군집에 동시에 속할 경우 간선 연결 확률은 독립적임
    + 예를 들어, 두 정점이 군집 A와 B에 동시에 속할 경우 두 정점이 간선으로 직접 연결될 확률은 1-(1-P_{A})(1-P_{B})
+ 어느 군집에도 홤께 속하지 않는 두 정점은 낮은 확률로 직접 연결
+ 중첩 군집 모형이 주어지면, 주어진 그래프의 확률을 계산할 수 있음
    + 1) 그래프의 각 간선의 두 정점이 (모형에 의해) 직접 연결될 확률
    + 2) 그래프에서 직접 연결되지 않은 각 정점 쌍이 (모형에 의해) 직접 연결되지 않을 확률

![캡처](https://user-images.githubusercontent.com/44515744/108938328-3d8f3e80-7693-11eb-8761-1f9b5406316c.PNG)

+ 중첩 군집 탐색은 주어진 그래프의 확률을 최대화하는 중첩 군집 모형을 찾는 과정
    + 통계 용어를 빌리면, 최우도 추정치를 찾는 과정
+ 중첩 군집 탐색을 요이하게 하기 위해 완화된 중첩 군집 모형을 사용
    + 완화된 중첩 군집 모형에서는 각 정점이 각 군집에 속해 있는 정도를 실숫값으로 표현
+ 최적화 관점에서는 모형의 매개변수들이 실수 값을 가지기 때문에 익숙한 최적화 도구 (경사하강법)을 사용해서 최적화할 수 있음

#### 9. 정리
+ 군집 구조와 군집 탐색 문제
    + 실제 그래프의 군집들은 무엇을 의미할까?
    + 군집을 어떻게 찾아낼까?

+ 군집 구조의 통계적 유의성과 군집성
    + 배치 모형과의 비교를 통해 군집성을 측정

+ 군집 탐색 알고리즘
    + 하향식 알고리즘 : Girvan-Newman 알고리즘
    + 상향식 알고리즘 : Louvain 알고리즘

+ 중첩이 있는 군집 탐색
    + (완화된) 중첩 군집 모형

+ 실습: Girvan-Newman 알고리즘 구현 및 적용

### [Graph 6강] 그래프를 추천시스템에 어떻게 활용할까? (기본)
#### 1. 우리 주변의 추천 시스템
+ 아마존에서의 상품 추천
    + Amazon.com 메인 페이지에는 고객 맞춤형 상품 목록을 보여줌
    + 같이사면 좋을 상품들을 추천
+ 넷플릭스에서의 영화 추천
    + 메인 페이지에는 고객 맞춤형 영화 목록을 보여줌
+ 유튜브에서의 영상 추천
    + 메인 페이지에는 고객 맞춤형 영상 목록을 보여줌
    + 현재 재생 중인 영상과 관련된 영상 목록을 보여줌
+ 페이스북에서는 추천하는 친구의 목록을 보여줌

#### 2. 내용 기반 추천시스템
+ 내용 기반(Content-based) 추천은 각 사용자가 구매/만족했던 상품과 유사한 것을 추천하는 방법
  + 동일한 장르의 영화를 추천
  + 동일한 감독의 영화 혹은 동일 배우가 출현한 영화를 추천하는 것
  + 동갑의 같은 학료를 졸업한 사람을 친구로 추천하는 것

#### 3. 내용 기반 추천 시스템의 원리
+ 1) 첫 단계는 사용자가 선호했던 상품들의 상품 프로필(Item Profile)을 수집하는 단계, 상품 프로필이란 해당 상품의 특성을 나열한 벡터(원-핫 인코딩)를 의미
+ 2) 사용자 프로필(User Profile)을 구성하는 단계, 사용자 프로필은 선호한 상품의 상품 프로필을 선호도를 사용하여 가중 평균하여 계산(사용자 프로필 역시 벡터)
    + 선호하는 정도를 가중치로 정의함
+ 3) 사용자 프로필과 다른 상품들의 상품 프로필을 매칭하는 단계, 사용자 프로필 벡터와 상품 프로필 벡터의 코사인 유사도를 계산(즉, 두 벡터 사이각의 코사인 값을 계산)
    + 코사인 유사도가 높을 수록, 해당 사용자가 과거의 선호했던 상품들과 해당 상품이 유사함을 의미
+ 4) 마지막 단계는 사용자에게 상품을 추천하는 단계, 계싼한 코사인 유사도가 높은 상품들을 추천

#### 4. 내용 기반 추천시스템의 장단점
+ 장점
    + 다른 사용자의 구매 기록이 필요하지 않음
    + 독특한 취향의 사용자에게도 추천이 가능
    + 새 상품에 대해서도 추천이 가능
    + 추천의 이유를 제공할 수 있음 (당신은 로맨스 영화를 서호했기 때문에, 새로운 로맨스 영화를 추천)
+ 단점
    + 상품에 대한 부가 정보가 없는 경우에 사용이 불가능
    + 구매 기록이 없는 사용자에게는 사용이 불가능
    + 과적합(Overfitting)으로 지나치게 협소한 추천을 할 위험이 있음

#### 5. 협업 필터링 추천시스템
+ 사용자-사용자 협업 필터링은 다음 세단계로 이루어짐
    + 1) 추천의 대상 사용자를 x라고 할 경우, x와 유사한 취향의 사용자를 찾음
    + 2) 유사한 취향의 사용자들이 선호한 상품을 찾음
    + 3) 이 상품들을 x에게 추천

#### 6. 협업 필터링의 원리
+ 사용자-사용자 협업 필터링의 핵심은 유사한 취향의 사용자를 찾는 것
+ 취향의 유사성은 상관 계수(Correlation Coefficient)를 통해 측정
    + 사용자 x의 상품 s에 대한 평점을 r_{xs} 라고 함
    + 사용자 x가 매긴 평균 평점을 \overline{r_{x}라고 함
    + 사용자 x와 y가 공동 구매한 상품들을 S_{xy}라고 함
    + 사용자 x와 y의 취향의 유사도는 아래 수식으로 계산(두 사용자의 평점 기준이 동일할 경우에는 양수 값, 다를 경우에는 음수 값을 반환)
        + (값 - 평균)을 기준으로한 코사인 유사도라고 생각

![캡처w](https://user-images.githubusercontent.com/44515744/109017974-081e3b80-76fb-11eb-84de-f9783730724b.JPG)

+ 구체적으로 취향의 유사도를 가중치로 사용한 평점의 가중 평균을 통해 평점을 추정함
    + 사용자 x의 상품 s에 대한 평점은 r_{xs}를 추정하는 경우를 생각함
    + 앞서 설명한 상관 계수를 이용하여 상품 s를 구매한 사용자 중에 x와 취향이 가장 유사한 k명의 사용자 N(x;s)를 뽑습니다.
+ 평점 r_{xs}는 아래의 수식을 이용해 추정

![캡처w](https://user-images.githubusercontent.com/44515744/109023494-305c6900-7700-11eb-969b-4d8c20b7305a.JPG)

+ 즉, 취향의 유사도를 가중치로 사용한 평점의 가중 평균을 계산함
+ 마지막 단계는 추정한 평점이 가장 높은 상품을 추천하는 단계
    + 추천의 대상 사용자를 x라고 하면, x가 구매하지 않은 상품 각각에 대해 평점을 추정함
    + 추정한 평점이 가장 높은 상품들을 x에게 추천함

#### 7. 협업 필터링의 장단점
+ 장점
    + 상품에 대한 부가 정보가 없는 경우에도 사용이 가능
+ 단점
    + 충분한 수의 평점 데이터가 누적되어야 효과적
    + 새 상품, 새로운 사용자에 대한 추천이 불가능
    + 독특한 취향의 사용자에게는 추천이 어려움

#### 8. 추천 시스템의 평가
+ 평점 데이터는 행렬로 볼 수 있음

![캡처](https://user-images.githubusercontent.com/44515744/109027071-c219a580-7703-11eb-9bc9-7d06af096e18.JPG)

+ 추천 시스템의 정확도
    + 1) 특정 사용자가 상품을 구매하면 행렬에 평점 정보를 입력하고 상품을 구매하지 않으면 빈칸으로 입력됨
    + 2) 데이터를 훈련 데이터, 평가 데이터를 구분하고 평가데이터는 값이 주어지지 없다고 가정
    + 3) 훈련 데이터를 이용해서 가리워진 평가 데이터의 평점을 추정함
    + 4) 추정한 평점과 실제 평가 데이터를 비교하여 오차를 측정함
        + 오차를 측정하는 지표로는 평균 제곱 오차(Mean Squared Error, MSE)가 많이 사용됨
        + 평가 데이터 내의 평점들의 집합을 T라고 함
        + 평균 제곱 오차는 아래 수식으로 계산함, |T|는 집합 T의 요소의 개수를 의미

    ![캡처](https://user-images.githubusercontent.com/44515744/109027185-df4e7400-7703-11eb-9c12-e8d5f1450c96.JPG)
    
    + 평균 제곱근 오차(Root Mean Squared Error, RMSE)도 많이 사용됨 

    ![캡처](https://user-images.githubusercontent.com/44515744/109027330-0442e700-7704-11eb-88f2-d23e408d15b8.JPG)
    
+ 이 밖에도 다양한 지표가 사용됨
    + 추정한 평점으로 순위를 매긴 후, 실제 평점으로 매긴 순위와의 상관 계수를 계산함
    + 추천한 상품 중 실제 구매로 이루어진 것의 비율을 측정하기도 함
    + 추천의 순서 혹은 다양성까지 고려하는 
