## [Day 30] AI + ML과 Quant Trading & AI Ethics
### (특강 7강) 구종만 - AI + ML 과 Quant Trading
#### 1. 퀀트 트레이딩 업계 소개
+ 투자(investment)와 트레이딩(trading) : 트레이딩은 상대적으로 단기간
+ 길어야 ~3일 정도의 보유기간
+ 퀀트 트레이딩
    + Quantitiative 계량적 트레이딩
    + 모델 기반 (가격이 특정 수학적 성질을 가진다고 가정 )
    + 혹은 데이터 기반 ( 시장의 과거 데이터에서 분포를 추정 ) 접근
    + Automated/system/algorithmic trading이라고 부름
+ 퀀텀 트레이딩의 스펙트럼
    + 포지션을 얼마나 오래 유지하는가? ( 1초 미만, ~3분, ~시간, ~하루, ~3일)
    + 어떤 상품군을 거랳는가?
    + 100% 자동화되었는가(블랙박스), 트레이더의 주관이 들어가는가(그레이박스)
    + 주문 집행(trade execution) vs 자체 수익
    + 어디에서 엣지가 오는가? (시장의 특성을 이용? 훌륭한 통계적 모델?)
+ 퀀트 트레이딩의 예1 : arbitrage
    + 싼 곳에서 사서 비싼 곳에서 판다 ( 거래소마다 가격이 다름 )
    + 아비트러지는 같은 상품의 가격을 맞춰주는 역할을 함
    + 개념적으로 간단하기 때문에 속도 경쟁이 치열
    + 90% 속도 + 10% 알파 경쟁
+ 마켓 메이킹 : 시장 조성자(market making)
    + 매수 주문과 매도 주문을 동시에 낸다
    + 두 주문이 동시에 체결되면 두 주문의 가격차만큼 이득
    + 유동성을 공급 : 누구나 거래하고 싶을 때 쉽게 사고 팔 수 있게함
    + 50% 속도, 50% 알파 경쟁
+ statistical arbitrage : 최근 호가 움직임을 이용한 가격 예측, 종목간의 상관관계를 이용한 가격 예측(cross section)
    + 데이터 기반 접근이 필수적, 오늘 주로 얘기할 주제
    + 10% 속도, 90% 알파
+ 퀀트 헤지펀드 / 로보 어드바이저
    + 고객의 자본을 운영하고 운용자금과 이익의 일부를 보수로 받음
    + 상대적으로 긴 보유기간
+ 프랍 트레이딩 (자기 자본 거래)
    + 회사 파트너들의 자본(수십~수백억)을 거래
    + 규모가 작은 대신 대개 HFT나 Market making을 통해 높은 수익률을 추구
+ 금융위기 이후 규제 변경으로 은행들은 자기자본 거래를 하지 않음
    + 퀀트 기반 트레이딩 서비스를 제공하는 쪽에 초점
+ 효율적 시장 가설 (Eugene Fama)
    + 가격은 상품에 대한 모든 정보를 포함하고 있기 때문에 장기적으로 초과수익을 얻을 수 는 없다
+ 미래가 예측 가능한 이유
    + 예측 범위에 따라 다르지만 미래를 예상할 수 있는 다양한 이유가 존재
    + 포지션이 큰 참가자들은 움직이는 데 오래 걸림
    + 큰 가격 변화가 있을 때 군중 심리가 나타남
    + 프로페셔널 참가자들은 리스크를 줄이는 합리적 행동을함
    + 새로운 정보가 시장에 반영되기까지는 시간이 걸림
    + 거래량이 많은 상품이나 거래소가 가격 발견 과정을 선도
+ 미래 예측에서 성능을 재는 기준 R-Square(결정계수)가 존재함
    + 엄청나게 많은 작은 예측들
    + 수천개의 종목에 하루에 수만번의 베팅
    + 각 베팅이 성공할 확률이 51%만 되어도, 수백만번 반복하면 이론값으로 수렴 (대수의 법칙)
    + HFT 전략의 평균 수익은 거래량의 대략 0.01%(1 basis point)!
+ 딥러닝을 안하는 이유
    + 근본적인 이유 : 시장에 영향을 미치는 수많은 원인 중 볼 수 있는 것은 극히 일부에 불과
    + 우리가 보는 정보도 항상 뒤늦게 보게될 수 밖에 없다.
    + 시장의 특성은 계속 변한다.
        + 참가자들은 접근 방법을 고도화하고, 계속 바뀐다. (가만히 있으면 모델이 점점 나빠짐 )
        + 내 모델과 다른 참가자들 모델 사이의 피드백
        + 달라지는 규제 조건
        + 새로운 시장 및 상품군의 출현
    + 털 한가닥만 보고 고양이인지 개인지 분류해야함
    + 고양이들이 분류를 피하기 위해 털 모양을 바꿈
    + 개와 고양이의 기준을 종종 정부가 바꿈
    + 문제가 어렵다 = 오버피팅의 위험이 너무 크다
        + 인샘플 에러를 낮추는 것은 쉽다
        + 기존 데이터 셋 내에서 완벽하게 오버피팅을 막았다고 하더라도 미래에도 오버피팅이 아닐지는 장담할 수 없음
        + 가장 쉬운 방법은 내가 무엇을 모델링하는지, 왜 그것이 의미있는지 알고 있는것 ( 선형회귀로도 대부분의 가치를 뽑아낼 수 있음)
+ 리서치를 하는 내용
    + 오렌지 : 새로운 정보
    + 쥬서기 : 새로운 정보에서 어떻게 요점만 뽑아낼 것인가?
    + 쥬스 : 알파
+ 리서치 과정 
    + 가설
        + 대부분의 리서치는 가설로 부터 시작
        + 설득력 있는 가설이 없이 시작된 리서치는 결론이 조금만 안 좋아도 끝나기 쉽다
        + 학습된 모델의 형태나 성능으로부터 점진적으로 더 나은 가설을 얻기도 함
    + 오렌지
        + 퀀트 트레이딩 회사들은 굉장히 다양한 데이터를 구입해 사용
        + 거래 시세, 공시자료
        + 뉴스, 트위터, 웹 크로링 결과, 애널리스트 리포트
        + 인공위성 사진, 날씨 정보, 신용카드 사용 정보 등
        + 어떻게 데이터에서 엑기스를 골라낼 것인가?
            + 필터링, 노이즈 제거, 클리핑, outlier 감지, 데이터 정규화, 리그레션 정규화 등
    + 쥬서기
        + 어떤 알고리즘이 내가 가진 가설을 가장 잘 표현하는가?
        + 내가 최적화하고 있는 목적함수가 정말 적절할까?
        + 기존에 공개된 코드를 사용하기엔 데이터가 너무 많은데 어떻게 스케일링해야할까?
            + 엔지니어링적 접근 (분산처리)
            + 모델링적 접근 (데이터 선별)
    + 쥬서기 이후
        + 어떤 거래소에 가서 거래할지?
        + 어떤 주문 타입을 쓸지?
        + 어떻게 포트폴리오를 관리해야 출렁임 없이 꾸준한 성능을 낼 수 있는지?
        + 어떻게 하면 내 트레이딩이 시장에 미치는 영향을 최소화할 수 있을지?
        + 등등 고려해야함
    + 리서치 과정에서 흔히 주의해야 하는 것들
        + 프로덕션 시스템과 백테스트 시스템의 차이
        + 마켓 임팩트(market impact, 가격충격) : 내 거래로 인해 시장에 어떻게 영향을 미치는지
        + 데이터 스누핑의 위험
            + 최근 거래량 많은 주식 위주로 백테스트하기
            + 거래 당일에는 아직 공개되지 않았던 데이터 사용 / 이후에 정정된 데이터 사용
            + 평균 거래량 등의 통계지수가 실수로 당일을 포함
            

### (특강 8강) 오혜연 - AI Ethics
#### 1. AI & Individuals
+ Bias
    + COMPAS : 범죄자의 재범확률을 AI가 확인해주는 시스템, 편향적인 문제가 심각하게 존재함(특정 인종 등에 결과가 치우침)
    + 입력데이터가 편향이 있으면 결과 데이터도 편향이 있음
    + 숨겨져있는 패턴 때문에 약자들이 배제되고 부정당할 수 있음

+ Target Variable & Class Labels
    + 타겟 변수와 클레스 변수를 정의하는 것부터 Bias가 많이 들어갈 수 있음
    + 좋은 직원을 여러 관점에서 정의할 수 있음
        + 오래 일하는 사람
        + 실적이 좋은 사람
        + 성별, 나이, 지역 등에 대한 Bias가 있을 수도 있음

+ Training Data: Labeling Examples
    + 누가 어떻게 Label을 하는지 bias가 생길 수 있음
    + 다르게 표현하자면 분류 기준을 어떻게 만드냐에 따라 bias가 생길 수 있음

+ Training Data: Collection
    + 데이터를 언제 어디에서 누가 수집을 했냐에 따라 문제가 발생할 수 있음
        + 스마트폰 데이터 기준으로 도로에 발생한 문제를 개선하려고 했으나, 이는 보급률이 떨어지는 가난한 지역의 데이터를 수집못하고 Bias가 발생함

+ Feature Selection
    + 거주지, 대학 등이 문제가 발생함 (Coarse granularity) 대학 내에서도 학과, 학점들이 있고 같은 대학이더라도 모두가 잘할 수 없음

+ Proxies (Unintentional discrimination)
    + 머신러닝은 패턴을 찾기 때문에, 의도치않은 의도가 개입될 수 있음

#### 2. AI & Society
+ AI를 의사결정에 사용할 경우, 편견들이 들어갈 수 있음
+ 많은 리소스를 갖고있는 회사에서는 이익이지만 소규모의 기업들에게는 AI 기술이 불리함
+ 자동화 시스템이 일자리를 대체하는 중, 채용자와의 관계가 약해질 수 있음
+ 딥페이크, 텍스트 제네레이터 등에서 가짜 정보가 생성될 수 있음

#### 3. AI & Humanity
+ 암 연구 등 의료분야에 AI가 활용됨
+ 언어모델을 하나 트레이닝할때 미국 동부에서 서부까지 가는 양의 에너지가 필요함
+ 전기 발전에 있어서 AI 솔루션을 활용하면 효율화할 수 있음
+ 운송수단에 있어서 AI 솔루션을 활용할 수 있음
    + 효율적인 배송
+ 건물에서의 AI 활용    
    + 빌딩에서 온수 사용을 예측하여 Heating을 조절
    + 도시 계획을 할때 사용자 동선을 예측하고 이를 최소화

